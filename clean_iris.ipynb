{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 - Set up\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "filepath = 'iris.data'\n",
    "\n",
    "df = pd.read_csv(filepath, names = ['sepal length','sepal width', 'petal length', 'petal width','class'])\n",
    "\n",
    "# dataframe converted into a numpy array\n",
    "nparray = df.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 - Select only relevant rows from a panda dataframe\n",
    "\n",
    "#binomial_rows = df.loc[ (df['class'] == 'Iris-setosa') & (df['class'] == 'Iris-versicolor')]\n",
    "binomial_rows = df.loc[df['class'] != 'Iris-virginica']\n",
    "\n",
    "partial_df = binomial_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2 - Select columns\n",
    "\n",
    "# numpy array with only the classes\n",
    "y_classes = partial_df.iloc[:,-1].values\n",
    "\n",
    "# numpy array with only the data values\n",
    "X_data = partial_df.iloc[:, :4].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 - Preprocessing\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Label encoding\n",
    "le = LabelEncoder()\n",
    "#le.fit(y_classes)\n",
    "#target_vector = le.transform(y_classes)\n",
    "y_target_vector = le.fit_transform(y_classes)\n",
    "\n",
    "# Standardize and normalize\n",
    "scaler = StandardScaler()\n",
    "X_scaled_data = scaler.fit_transform(X_data)\n",
    "\n",
    "# Separate training sets from testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled_data, y_target_vector, test_size = 0.33, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3 - Model\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial').fit(X_train, y_train)\n",
    "logreg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 - Model from scratch to compare\n",
    "\n",
    "def pi(Z):\n",
    "    return 1/(1+np.exp(-Z))\n",
    "\n",
    "def C(X,W):\n",
    "    return X.dot(W)\n",
    "\n",
    "def gradient(matX,y,j,W):\n",
    "    # j represents the index of the model's coefficient\n",
    "    grad = 0\n",
    "    for index, X in enumerate(matX):\n",
    "        Z = C(X,W)\n",
    "        grad += X[j] * (y[index] - pi(Z))\n",
    "    return grad\n",
    "\n",
    "def optModel(matrix_X, vector_y, learning_rate=0.5, max_iter=500):\n",
    "    # 5-value vector for omega\n",
    "    W = np.array([1,1,1,1,1])\n",
    "    \n",
    "    column_of_ones = np.ones((matrix_X.shape[0], 1))\n",
    "    matrix_X = np.concatenate((column_of_ones , matrix_X), axis=1)\n",
    "    \n",
    "    for i in range(max_iter):\n",
    "        for index, w in enumerate(W):\n",
    "            W[index] = w - learning_rate * gradient(matrix_X, vector_y, index, W)\n",
    "    return W\n",
    "\n",
    "def evaluation(matrix_X, vector_y, model_W):\n",
    "    success = 0\n",
    "    \n",
    "    column_of_ones = np.ones((matrix_X.shape[0], 1))\n",
    "    matrix_X = np.concatenate((column_of_ones , matrix_X), axis=1)\n",
    "    \n",
    "    for i, vector_X in enumerate(matrix_X):\n",
    "        Z = C(vector_X,model_W)\n",
    "        proba = pi(Z)\n",
    "        print(\"p=\"+str(proba)+\" and y[\"+str(i)+\"]=\"+str(vector_y[i]))\n",
    "        \n",
    "        if proba < 0.5:\n",
    "            if vector_y[i] == 1:\n",
    "                success += 1\n",
    "        else:\n",
    "            if vector_y[i] == 0:\n",
    "                success += 1\n",
    "    \n",
    "    return success/len(matrix_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p=0.5419508007169671 and y[0]=1\n",
      "p=0.33709435705717783 and y[1]=1\n",
      "p=0.772728799752916 and y[2]=1\n",
      "p=0.6903059275343927 and y[3]=0\n",
      "p=0.9234722076254455 and y[4]=0\n",
      "p=0.8383521896850494 and y[5]=0\n",
      "p=0.8877789833202385 and y[6]=0\n",
      "p=0.3857641793649453 and y[7]=1\n",
      "p=0.9071539671900479 and y[8]=0\n",
      "p=0.8649627094215859 and y[9]=0\n",
      "p=0.9234722076254455 and y[10]=0\n",
      "p=0.733541766050115 and y[11]=0\n",
      "p=0.5937080532976522 and y[12]=1\n",
      "p=0.9656087026268628 and y[13]=0\n",
      "p=0.48927202736637676 and y[14]=1\n",
      "p=0.8877789833202385 and y[15]=0\n",
      "p=0.5937080532976522 and y[16]=1\n",
      "p=0.6903059275343927 and y[17]=1\n",
      "p=0.6903059275343927 and y[18]=0\n",
      "p=0.8383521896850494 and y[19]=0\n",
      "p=0.5937080532976522 and y[20]=1\n",
      "p=0.6903059275343927 and y[21]=1\n",
      "p=0.8383521896850494 and y[22]=0\n",
      "p=0.772728799752916 and y[23]=0\n",
      "p=0.4368304563552064 and y[24]=1\n",
      "p=0.9771834741117076 and y[25]=0\n",
      "p=0.8649627094215859 and y[26]=0\n",
      "p=0.6434644496168845 and y[27]=1\n",
      "p=0.733541766050115 and y[28]=0\n",
      "p=0.4368304563552064 and y[29]=1\n",
      "p=0.8383521896850494 and y[30]=0\n",
      "p=0.772728799752916 and y[31]=0\n",
      "p=0.8383521896850494 and y[32]=1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7272727272727273"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelingafb = optModel(X_train, y_train,learning_rate=0.05, max_iter=1)\n",
    "\n",
    "evaluation(X_test, y_test, modelingafb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(modelingafb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
